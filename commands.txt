
https://www.udemy.com/elasticsearch-7-and-elastic-stack/

===============================================================================
get sample data:

wget http://media.sundog-soft.com/es7/shakes-mapping.json
wget http://media.sundog-soft.com/es7/shakespeare_7.0.json

wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip
unzip ml-latest-small.zip

wget for windows:
https://builtvisible.com/download-your-website-with-wget/
https://eternallybored.org/misc/wget/

https://www.csvjson.com/csv2json

===============================================================================
curl command:

curl -H "Content-Type: application/json" -X<verb> <URL> -d '<body>'

===============================================================================
load sample data:

curl -H "Content-Type: application/json" -XPUT localhost:9200/shakespeare --data-binary @shakes-mapping.json 
curl -H "Content-Type: application/json" -XPOST localhost:9200/shakespeare/_bulk --data-binary @shakespeare_7.0.json

curl -H "Content-Type: application/json" -XDELETE localhost:9200/shakespeare 

===============================================================================
search with key words:

curl -H "Content-Type: application/json" -XGET 'localhost:9200/shakespeare/_search?pretty' -d '{"query": {"match_phrase": {"text_entry": "to be or not to be"}}}'

===============================================================================
docker commands:

ssh into a container:
docker exec -it <container name> bash
docker ps
winpty docker exec -it 57ee70cf8be6 bash

run a command in a image:
docker run -it <image name> <command>
winpty docker run -it elasticsearch:7.2.0 ls

run a command in a container:
docker-compose run <container name> <command>
docker-compose run es01 ls

copy fils from container to host:
docker cp d347d3715e28:/usr/share/logstash/config/ .

===============================================================================

# do this in postman instead!!!
nano cl - "curl -H "Content-Type: application/json" "$@"
chmod a+x cl
. cl localhost:9200

wget http://media.sundog-soft.com/es7/movies.json
curl -H "Content-Type: application/json" -XPUT localhost:9200/_bulk?pretty --data-binary @movies.json 

wget http://media.sundog-soft.com/es7/series.json
# copy to Postman working directory
cp series.json ~/Postman/files/

===============================================================================
# logstash

wget media.sundog-soft.com/es/access_log

===============================================================================

wget http://files.grouplens.org/datasets/movielens/ml-100k.zip

create database movielens;
create table movielens.movies (movidID int primary key not null, title text, releaseDate date);
drop table movielens.movies;
load data local infile '/c:/Users/james.wang/git/elasticsearch/elm/ml-100k/u.item' into table movielens.movies fields terminated by '|' (movieID, title, @var3) set releaseDate = str_to_date(@var3, '%d-%M-%Y');
select * from movielens.movies where title like 'star%';
select * from movielens.movies;

C:\Users\james.wang\eclipse-workspace\digicert_docker:
docker-compose up -d digisql

https://www.elastic.co/blog/how-to-keep-elasticsearch-synchronized-with-a-relational-database-using-logstash
C:\Users\james.wang\git\elasticsearch\el.mariadb:
docker-compose up -d elasticsearch
docker-compose up logstash

https://qbox.io/blog/import-csv-elasticsearch-logstash-sincedb
https://www.youtube.com/watch?v=rKy4sFbIZ3U
https://www.dataneb.com/post/loading-csv-data-into-elasticsearch-with-logstash
https://www.elastic.co/guide/en/logstash/current/plugins-filters-mutate.html
https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html
C:\Users\james.wang\git\elasticsearch\el.csv:
docker-compose up -d elasticsearch
docker-compose up logstash

===============================================================================



===============================================================================


































